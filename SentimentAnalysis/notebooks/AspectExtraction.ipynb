{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule based aspect extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [A Rule-Based Approach to Aspect Extraction from Product Reviews](https://aclanthology.org/W14-5905) (Poria et al., 2014) we implement the rules as 8 separed functions and we apply them to the reviews in series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other approaches and libraries. I coose this approach because of its simplicity (implementation time) and the control I have over it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspect-based opinion mining focuses on the extraction of aspects (or product features) from opinionated text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explicit** aspects explicitly denote targets \n",
    "  - e.g. I love the *touchscreen* of my phone but the *battery life* is so short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspect can also be expressed indirectly through an **implicit aspect clue** (IAC)\n",
    "    - e.g. This is the best phone one could have. It is *lightweight*, *sleek* and *attractive*. I found it very *user-friendly* and *easy to manipulate*\n",
    "    - `lightweight` -> weight; \n",
    "    - `sleek` and `attractive`  -> appearance; \n",
    "    - `user-friendly`  -> interface; \n",
    "    - `easy to manipulate` -> functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Detect explicit aspects and IACs from opinionated documents.\n",
    "* Map IACs to their respective aspect **categories**.\n",
    "* IACs = single words (`sleek`) or multi-word expressions (`easy to manipulate`); different part-of-speech (POS) (adjectives, noun, verbs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed aspect parser is based on two general rules:\n",
    "1. Rules for the sentences having subject verb.\n",
    "2. Rules for the sentences which do not have subject verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the NLP library with a pre-trained NLP model. For the use we are intereseted in we can avoid loading in the SpaCy pipeline the `EntityRecognizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md', exclude=\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the senticnet lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "senticnet = pd.read_csv(\"senticnet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aspect_estraction import Aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool. It is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(doc):\n",
    "    for t in doc:\n",
    "        print(t, t.dep_, t.pos_,t.tag_, [c for c in t.children], t.head,t.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senticnet_search(query):\n",
    "    '''Search if {query} list of word is present in the senticnet list'''\n",
    "    processed_query = (\"_\".join(query)).lower()\n",
    "    return not senticnet[senticnet[\"Aspect\"] == processed_query].empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject Noun Rule:\n",
    "* **Trigger**: token is a syntactic subject\n",
    "* **Behavior**: if token *h* subject-noun (nsubj) relationship with word t:\n",
    "    - if t has any adverbial or adjective modifier = t aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if t has any adverbial or adjective modifier and the modifier exists in SenticNet, then t is extracted as an aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule1(doc):\n",
    "    '''\n",
    "    Aspect extraction following Subject Noun Rule 1\n",
    "    There is a subject of t that has any adverbial or adjective modifier.\n",
    "    T is the aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"amod\", \"advmod\"] and not token.head.is_stop:\n",
    "                    if senticnet_search([token.head.lemma_]):\n",
    "                        return Aspect(aspect=token.head.lemma_, rule=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This mp3 player also costs a lot less than the ipod.\")\n",
    "rule1(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if the sentence does not have auxiliary verb, i.e., `is`, `was`, `would`, `should`, `could`, then:\n",
    "    - if the verb t is modified by an adjective or an adverb or it is in adverbial clause modifier relation with another token, then both h and t are extracted as aspects. In EX, battery is in a subject relation with lasts and lasts is modified by the adjective modifier little, hence both the aspects last and battery are extracted.\n",
    "      - *The battery lasts little.*\n",
    "    - if t has any direct object relation with a token n and the POS of the token is `Noun` then n is extracted as an aspect. In EX, like is in direct object relation with lens so the aspect lens is extracted. \n",
    "      - *I like the lens of this camera.*\n",
    "    - if t has any direct object relation with a token n and the POS of the token is `Noun`, then the token n extracted as aspect. In the dependency parse tree of the sentence, if another token n1 is connected to n using any dependency relation and the POS of n is Noun, then n1 is extracted as an aspect. In (3), like is in direct object relation with beauty which is connected to screen via a preposition relation. So the aspects screen and beauty are extracted.\n",
    "      - *I like the beauty of the screen.*\n",
    "    - if t is in open clausal complement relation with a token t1 , then the aspect t-t1 is extracted if t-t1 exists in the opinion lexicon. If t1 is connected with a token t2 whose POS is Noun, then t2 is extracted as an aspect. In EX, like and comment is in clausal complement relation and comment is connected to camera using a preposition relation. Here, the POS of camera is Noun and, hence, camera is extracted as an aspect.\n",
    "      - I would like to comment on the camera of this phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule2(doc):\n",
    "    '''\n",
    "    Aspect extraction following Subject Noun Rule 2\n",
    "    Sentence without auxiliary verbs and t with adjective, adverbial or adverbial modifier clause with another token -> h and t are aspects\n",
    "    or with direct object relation with a NOUN n, n is aspect if in SentiNet\n",
    "    or with direct object relation with a NOUN n and not in SentiNet derive list of connected nouns and that is aspect\n",
    "    or open clausal complement with another token\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            #check if an AUX is present\n",
    "            aux_presence = [t for t in doc if t.pos_ == \"AUX\"]\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"amod\", \"advmod\", \"advcl\"] and not aux_presence and not token.is_stop:\n",
    "                    return Aspect(aspect=token.lemma_, rule=2)\n",
    "                if child.dep_ == \"dobj\" and child.pos_ == \"NOUN\" and not aux_presence and not child.is_stop:\n",
    "                    if senticnet_search([child.lemma_]):\n",
    "                        return Aspect(aspect=child.lemma_, rule=2)\n",
    "                    else:\n",
    "                        tmp = \" \".join([child.lemma_]+[cococ.lemma_ for coc in child.children if coc.pos_ ==\n",
    "                                \"ADP\" for cococ in coc.children if cococ.pos_ == \"NOUN\"])\n",
    "                        return Aspect(aspect=tmp,  rule=2)\n",
    "\n",
    "                if child.dep_ == \"xcomp\" and not child.is_stop:\n",
    "                    #if [child,coc] is in SenticNet\n",
    "                    tmp = [[child.lemma_, coc.lemma_] for coc in child.children]\n",
    "                    for coc in child.children:\n",
    "                        if senticnet_search([child.lemma_, coc.lemma_]) or senticnet_search([coc.lemma_,child.lemma_]):\n",
    "                            return Aspect(aspect=\" \".join([child.lemma_, coc.lemma_]), rule=2)\n",
    "                    else:\n",
    "                        tmp = [\n",
    "                            cococ.lemma_ for coc in child.children for cococ in coc.children if cococ.pos_ == \"NOUN\"]\n",
    "                        if tmp:\n",
    "                            return Aspect(aspect=\" \".join(tmp), rule=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The battery lasts little.\")\n",
    "print(f\"EXAMPLE 1: {doc}\")\n",
    "print(rule2(doc))\n",
    "\n",
    "doc = nlp(\"I like the lens of this camera.\")\n",
    "print(f\"EXAMPLE 2: {doc}\")\n",
    "print(rule2(doc))\n",
    "\n",
    "doc = nlp(\"I like the beauty of the screen.\")\n",
    "print(f\"EXAMPLE 3: {doc}\")\n",
    "print(rule2(doc))\n",
    "\n",
    "doc = nlp(\"I would like to comment on the camera of this phone.\")\n",
    "print(f\"EXAMPLE 4: {doc}\")\n",
    "print(rule2(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A copula is the relation between the complement of a copular verb and the copular verb. If the token t is in copula relation with a copular verb and the copular verb exists in the implicit aspect lexicon, then t is extract as aspect term. In EX, expensive is extracted as an aspect.\n",
    "  - *The car is expensive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule3(doc):\n",
    "    '''\n",
    "    Subject Noun Rule\n",
    "    Sentence with auxiliary verb (copula) and token as complement -> token is aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"acomp\"] and token.head.pos_ == \"AUX\" and not child.is_stop:\n",
    "                    #check if child exists in the implicit aspect lexicon\n",
    "                    #print(child)\n",
    "                    return Aspect(aspect=child.lemma_, rule=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The car is expensive.\")\n",
    "rule3(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the token t is in copula relation with a copular verb and the POS of h is Noun, then h is extracted as an explicit aspect. In EX, camera is extracted as an aspect. \n",
    "  - *The camera is nice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule4(doc):\n",
    "    '''\n",
    "    Subject Noun Rule\n",
    "    Sentence with auxiliary verb (copula) and token as complement and a Noun -> noun is aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"acomp\"] and token.head.pos_ == \"AUX\" and token.pos_ == \"NOUN\" and not token.is_stop:\n",
    "                    return Aspect(aspect=token.lemma_, rule=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The camera is nice.\")\n",
    "print(rule4(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the token t is in copula relation with a copular verb and the copular verb is connected to a token t1 using any dependency relation and t1 is a verb, then both t1 and t are extracted as implicit aspect terms, as long as they exist in the implicit aspect lexicon. In EX, lightweight is in copula relation with is and lightweight is connected to the word carry by open clausal complement relation. Here, both lightweight and carry are extracted as aspects.\n",
    "  - *The phone is very lightweight to carry.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule5(doc):\n",
    "    '''\n",
    "    Subject Noun Rule\n",
    "    Sentence with auxiliary verb (copula) and token as complement and a Noun -> noun is aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"acomp\"] and token.head.pos_ == \"AUX\" and not child.is_stop:\n",
    "                    # check if  child and coc exists in the implicit aspect lexicon\n",
    "                    tmp = \" \".join(\n",
    "                        [child.lemma_]+[coc.lemma_ for coc in child.children if coc.pos_ == \"VERB\"])\n",
    "                    return Aspect(aspect=tmp, rule=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(\"The phone is very lightweight to carry.\")\n",
    "rule5(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON subject noun rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if an `adjective` or `adverb` h is in `infinitival` or `open clausal complement` (ccomp, xcomp) relation with a token t and h exists in the implicit aspect lexicon, then h is extracted as an aspect. In EX, big is extracted as an aspect as it is connected to hold using a clausal complement relation.\n",
    "    - Very big to hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule6(doc):\n",
    "    '''\n",
    "    NO Subject Noun Rule\n",
    "    Sentence with adjective or adverb h in infinitival or open clausal complement -> if h in IAC lexicon -> h aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"ADJ\", \"ADV\"]:\n",
    "            for child in token.children:\n",
    "                if child.dep_ in [\"ccomp\", \"xcomp\"] and not token.is_stop:\n",
    "                    # if token is in IAC lexicon\n",
    "                    return Aspect(aspect=token.lemma_, rule=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Very big to hold.\")\n",
    "rule6(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if a token h is connected to a noun t using a prepositional relation, then both h and t are extracted as aspects. In EX, sleekness is extracted as an aspect.\n",
    "    - *Love the sleekness of the player.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule7(doc):\n",
    "    '''\n",
    "    NO Subject Noun Rule\n",
    "    h token connected to noun t through preposition -> h+t aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"prep\":\n",
    "                for child_of_child in child.children:\n",
    "                    if child_of_child.pos_ == \"NOUN\" and not token.is_stop:\n",
    "                        return Aspect(aspect=f\"{token.lemma_} {child_of_child.lemma_}\", rule=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Love the sleekness of the player.\")\n",
    "rule7(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if a token h is in a direct object relation (`dobj`) with a token t, t is extracted as aspect. In EX, mention is in a direct object relation with price, hence price is extracted as an aspect.\n",
    "    - Not to mention the price of the phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule8(doc):\n",
    "    '''\n",
    "    NO Subject Noun Rule\n",
    "    h token connected with direct object with t -> t aspect\n",
    "    '''\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"dobj\" and not child.is_stop:\n",
    "                return Aspect(aspect=child.lemma_, rule=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Not to mention the price of the phone.\")\n",
    "rule8(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I am ignoring these two additional rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each aspect term extracted above, if an aspect term h is in co-ordination or conjunct relation with another token t, then t is also extracted as an aspect. In EX, amazing is firstly extracted as an aspect term. As amazing is in conjunct relation with easy, then use is also extracted as an aspect.\n",
    "    - *The camera is amazing and easy to use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule1(token):\n",
    "    '''\n",
    "    Additional Rule 1. \n",
    "    Takes care of the cases where the aspect is hidden by conjunctions \n",
    "    '''\n",
    "    print([coc for c in token.children if c.dep_ in [\"conj\"]\n",
    "            for coc in c.children if coc.dep_ == \"xcomp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The camera is amazing and easy to use.\")\n",
    "rule3(doc)\n",
    "add_rule1(doc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A noun compound modifier of an NP is any noun that serves to modify the head noun. If t is extracted as an aspect and t has noun compound modifier h, then the aspect h-t is extracted and t is removed from the aspect list. In EX, as chicken and casserole are in noun compound modifier relation, only chicken casserole is extracted as an aspect.\n",
    "  - *We ordered the chicken casserole, but what we got were a few small pieces of chicken, all dark meat and on the bone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule2(token):\n",
    "    '''\n",
    "    Additional Rule 2. \n",
    "    Takes care of coumpound nouns\n",
    "    '''\n",
    "    print([c for c in token.children if c.dep_ == \"compound\" and c.pos_==\"NOUN\"]+[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"We loved the chicken casserole.\")\n",
    "rule2(doc)\n",
    "\n",
    "add_rule2(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectRule = {\"rule1\": rule1, \"rule2\": rule2, \"rule3\": rule3, \n",
    "               \"rule4\": rule4, \"rule5\": rule5}\n",
    "NoSubjectRule = {\"rule6\": rule6, \"rule7\": rule7, \"rule8\": rule8}\n",
    "\n",
    "def extract_aspect_sentence(doc):\n",
    "    '''Extract the aspects from a sentence'''\n",
    "    subjects = [token for token in doc if token.dep_ in [\"nsubj\", \"nsubjpass\"]]\n",
    "    aspects =[]\n",
    "    if subjects:\n",
    "        for name, rule in SubjectRule.items():\n",
    "            if a:=rule(doc):\n",
    "                if a not in aspects:\n",
    "                    a.sentiment = sia.polarity_scores(doc.text).get('compound')\n",
    "                    aspects.append(a)\n",
    "\n",
    "    else:\n",
    "        for name, rule in NoSubjectRule.items():\n",
    "            if a := rule(doc):\n",
    "                if a not in aspects:\n",
    "                    a.sentiment = sia.polarity_scores(doc.text).get('compound')\n",
    "                    aspects.append(a)\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspects(text: str, nlp: spacy.lang.en.English):\n",
    "    doc = nlp(text)\n",
    "    aspects = []\n",
    "    for sent in doc.sents:\n",
    "        tmp_aspects = extract_aspect_sentence(sent)\n",
    "        aspects += tmp_aspects\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aspects(\"I brought it because I thought it would make my house smell like a Christmas tree but the smell is very dull and I have to leave it lit for a very long time to get even a modest smell in the house from it. This was my first buying this brand of candle and expected a stronger scent based off of what people told me. I smelled other candles at Walmart from Yankee and they were stronger so I think it might just be this scent.\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aspects(\"This candle has NO SCENT at all. The worst candle I have ever purchased. I'm never buying a Yankee candle again. First time purchase by this brand, and the last.\", nlp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8915c1abd490d094a9c0bd3efca1aaafbc86b5f7bcd7166c84b94176c5db6f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('scrapeamazon': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
